{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.kaggle.com/competitions/cisc-873-dm-f22-a3"
      ],
      "metadata": {
        "id": "EEhhhuNbX4TP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtuxWrmAvyuK"
      },
      "source": [
        "# **Problem Formulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQBzJA9Uv-EJ"
      },
      "source": [
        "**Problem:** There is a lot of false information on the internet, so we need to clean this information to determine if this information is fake news or not.\n",
        "\n",
        "**Inputs:** Two columns(text and lable)\n",
        "\n",
        "**Output:** Is the information fake or not\n",
        "\n",
        "**Function required:** Classification & Prediction\n",
        "\n",
        "**Challenges:** \\\n",
        "1. Remove stopwords, html tags, single letter, and multiple space.\n",
        "2. Use Tdf-ift.\n",
        "3. Determine siutable Classifier.\n",
        "4. Use cross validation\n",
        "5. Select optimal hyperparameters in each algorithm.\n",
        "6. Find best accuracy.\n",
        "\n",
        "**What is the impact?**\n",
        "* If the model predicts the type of news correctly, this means they will not wait to know if the news is fake or not, as the model will tell them the type of news, so they can save time waiting to know if the news is fake or not.\n",
        "\n",
        "**What is the ideal solution?**\n",
        "* The **Neural Network** model is the best solution by using **Random** search and Word-level Vectorizer.\n",
        "* Accuracy **0.82669**(public) **0.82914**(private) in kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXCqP67YXVls"
      },
      "source": [
        "# **Trials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7opYAnLnap5E"
      },
      "source": [
        "## **Common Commands** in all models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHYdmY69XkRt"
      },
      "source": [
        "**What is the experimental protocol used and how was it carried out?** \\\n",
        "1. Read Training and Testing Data \n",
        "2. Data Preprocessing using Pipline \n",
        "3. Splitting data\n",
        "4. Validation set\n",
        "5. PipeLine\n",
        "4. Tuning hyperparameters\n",
        "5. Built model\n",
        "* I used the validation set.\n",
        "\n",
        "**What preprocessing steps are used?**\n",
        "\n",
        "1. Remove html tags.\n",
        "2. Remove stopwords.\n",
        "3. Remove single letter.\n",
        "4. Remove multiple spaces.\n",
        "5. Convert all letters to lower case.\n",
        "6. Join all words in text_clean and separate them by space.\n",
        "7. Taking any text that's length is greater than 25\n",
        "8. Convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "9. Normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inwm5qPoGMGh"
      },
      "source": [
        "##### Import liberaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kH2rJWewcfbr",
        "outputId": "4795c1af-b1c4-4c8a-d3a4-f04d8f6bd1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-optimize # install scikit-optimize to be able to use bayesian search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIg9u0bDoXt8"
      },
      "outputs": [],
      "source": [
        "#import liberaries that I will use in my code\n",
        "import re\n",
        "import pickle\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holoviews as hv # HoloViews is an open-source Python library designed to make data analysis and visualization seamless and simple. \n",
        "import nltk # NLTK is a standard Python package with prebuilt functions and utilities for quick and easy use.\n",
        "from bokeh.io import output_notebook # It is used to create interactive visualisations for modern web browsers and to build graphics.\n",
        "output_notebook()\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# some seeting for pandas and hvplot\n",
        "\n",
        "pd.options.display.max_columns = 100 # Determine the maximum number of columns that I want to appear when displaying the dataframe\n",
        "pd.options.display.max_rows = 300 # Determine the maximum number of rows that I want to appear when displaying the dataframe\n",
        "pd.options.display.max_colwidth = 100 # Maximum width of columns\n",
        "np.set_printoptions(threshold=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X95Lit1qZurb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NAQFMRUaPwt",
        "outputId": "a5665596-7b00-4306-9ba1-596324ecb968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#connect to my drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZDj6MYdbJE8"
      },
      "source": [
        "##### Read Training and Testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haSjfQKGaTAE",
        "outputId": "c7d7a883-a3e9-4884-80e7-958c3c9721c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  265723   \n",
              "1  284269   \n",
              "2  207715   \n",
              "3  551106   \n",
              "4    8584   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      0  \n",
              "4      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9853bcc6-89fe-4a77-a677-c8741664cfb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9853bcc6-89fe-4a77-a677-c8741664cfb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9853bcc6-89fe-4a77-a677-c8741664cfb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9853bcc6-89fe-4a77-a677-c8741664cfb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Read all our training data by using read_csv, which takes the path of the file with the extension that I want to read.\n",
        "data_tr = pd.read_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/xy_train.csv')\n",
        "# Based on position, this function returns the first 5 rows of the dataset. It's used to quickly see if our dataset contains the proper kind of data.\n",
        "data_tr.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uSmq39rabjY",
        "outputId": "f9923308-f300-4e5f-92d1-f01bad8edb29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                                            text\n",
              "0   0                                                      stargazer \n",
              "1   1                                                            yeah\n",
              "2   2      PD: Phoenix car thief gets instructions from YouTube video\n",
              "3   3  As Trump Accuses Iran, He Has One Problem: His Own Credibility\n",
              "4   4                                    \"Believers\" - Hezbollah 2011"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e84c928b-8268-42d5-b7d9-6f46894837ad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e84c928b-8268-42d5-b7d9-6f46894837ad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e84c928b-8268-42d5-b7d9-6f46894837ad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e84c928b-8268-42d5-b7d9-6f46894837ad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Read all our testing data by using read_csv, which takes the path of the file with the extension that I want to read.\n",
        "data_ts = pd.read_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/x_test.csv')\n",
        "# Based on position, this function returns the first 5 rows of the dataset. It's used to quickly see if our dataset contains the proper kind of data.\n",
        "data_ts.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xl_Iq1A48o7y",
        "outputId": "2e021e0d-1d27-4ff6-b352-982ff6fe8b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'text', 'label'], dtype='object')\n",
            "Index(['id', 'text'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Display the column's name in training and testing data\n",
        "print(data_tr.columns)\n",
        "print(data_ts.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUNKxyseA-_E"
      },
      "source": [
        "##### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug1LefLKqfL7",
        "outputId": "541d204a-78ec-42d0-eef0-e24adc1a729e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")   # It is the method used to return the word to its original form\n",
        "stop_words = set(stopwords.words(\"english\")) # It is the method of producing a stop words\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    # IGNORECASE : is a flag allows for case-insensitive matching of the Regular Expression with the given string\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE) # Remove any more than one space\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\") # Remove web tags\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE) # Remove any leter does not english charachter\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE) # Remove any single character\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)# Replace any tag with a single space.\n",
        "    text = re.sub(RE_ASCII, \" \", text) # Replace any non english character with a single space.\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text) # Replace any single character with a single space.\n",
        "    text = re.sub(RE_WSPACE, \" \", text)  # Replace any more than one space with a single space.\n",
        "\n",
        "    word_tokens = word_tokenize(text) # split the sentence into words\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens] # Convert all letters to small letters\n",
        "\n",
        "    # words_filtered (Words can be filtered based on how many times they appear)\n",
        "    # stemmer used to return the word to its original form.\n",
        "    words_filtered = [\n",
        "        stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "    ]\n",
        "\n",
        "    # Join all words in text_clean and separate them by space.\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ti4Eh8Nr_4c",
        "outputId": "b55421ac-27c3-40d9-b796-69405a50c7b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'python basic program languag'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# call clean_text function that take string as a parameter to test the function\n",
        "clean_text(\"Python is a basic programming language .\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgp6f477r_5Y"
      },
      "outputs": [],
      "source": [
        "# Clean texts by taking any text that's length is greater than 25\n",
        "data_tr['clean_text']=data_tr.loc[data_tr['text'].str.len()>25,\"text\"]\n",
        "data_ts['clean_text']=data_ts.loc[data_ts['text'].str.len()>0,\"text\"]\n",
        "\n",
        "# map is an iterator function that returns a result after applying a clean_text function to each item in an iterable \n",
        "# lambda is a function used to apply certain functions to all rows of a data set.\n",
        "# lambda take one argument (x) then put x in clean_text function\n",
        "# if statement means ( if input x is string enter x to clean_text function then the result put in data['clean_com'] if not return x in data['clean_com'] as it is  )\n",
        "data_tr['clean_text']=data_tr['clean_text'].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x   \n",
        ")\n",
        "data_ts['clean_text']=data_ts['clean_text'].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x   \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GVm5gux3r_6H",
        "outputId": "08f0ec13-7f17-4c7c-be42-644fa2899631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  \\\n",
              "0          0   \n",
              "1          1   \n",
              "2          2   \n",
              "3          3   \n",
              "4          4   \n",
              "...      ...   \n",
              "59146  59146   \n",
              "59147  59147   \n",
              "59148  59148   \n",
              "59149  59149   \n",
              "59150  59150   \n",
              "\n",
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            clean_text  \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-269cbdf8-161b-4a2a-a5bb-7cac337326ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-269cbdf8-161b-4a2a-a5bb-7cac337326ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-269cbdf8-161b-4a2a-a5bb-7cac337326ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-269cbdf8-161b-4a2a-a5bb-7cac337326ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umamQkkEr_66",
        "outputId": "309a3994-f039-401c-c5c7-14740ee051dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32172\n",
              "1    27596\n",
              "2      232\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Examine the label column for unique values and the number of times they appear.\n",
        "data_tr['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGKgToSEsXUN"
      },
      "outputs": [],
      "source": [
        "# drop rows that has label = 2 \n",
        "index_2=data_tr['label']==2\n",
        "index_2\n",
        "data_tr.drop(data_tr.index[index_2],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcfYrrOksXVD",
        "outputId": "2fce72ff-ed0c-4bba-b716-a9e2cc564871"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32172\n",
              "1    27596\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Examine the label column for unique values and the number of times they appear.\n",
        "data_tr['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcBpDySOsXV5"
      },
      "outputs": [],
      "source": [
        "# copy data in data_clean\n",
        "data_tr_clean=data_tr.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0K09Rm5bsXWl",
        "outputId": "de615b56-3078-4b2b-fb0d-63ee76b75bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id  \\\n",
              "0  265723   \n",
              "1  284269   \n",
              "2  207715   \n",
              "3  551106   \n",
              "4    8584   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1  British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2  In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3  Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4  Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "\n",
              "   label  \\\n",
              "0      0   \n",
              "1      0   \n",
              "2      0   \n",
              "3      0   \n",
              "4      0   \n",
              "\n",
              "                                                                                            clean_text  \n",
              "0  group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "1  british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "2  goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "3  happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "4  obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-389c317a-4a51-4f81-885f-89fef96f6e77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-389c317a-4a51-4f81-885f-89fef96f6e77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-389c317a-4a51-4f81-885f-89fef96f6e77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-389c317a-4a51-4f81-885f-89fef96f6e77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data_tr_clean.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUC_fJXbsXd4",
        "outputId": "08358db1-6b18-4899-c492-37e5fe6c3dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "one         3285\n",
              "like        3128\n",
              "new         2998\n",
              "look        2847\n",
              "color       2737\n",
              "man         2729\n",
              "get         2602\n",
              "trump       2578\n",
              "say         2347\n",
              "peopl       2316\n",
              "use         2307\n",
              "first       2248\n",
              "make        2227\n",
              "old         2226\n",
              "time        2027\n",
              "poster      2000\n",
              "found       1999\n",
              "day         1935\n",
              "war         1858\n",
              "post        1648\n",
              "world       1570\n",
              "work        1531\n",
              "show        1513\n",
              "us          1506\n",
              "american    1504\n",
              "take        1491\n",
              "life        1482\n",
              "psbattl     1470\n",
              "help        1442\n",
              "go          1420\n",
              "state       1409\n",
              "back        1369\n",
              "two         1364\n",
              "school      1345\n",
              "see         1329\n",
              "photo       1324\n",
              "made        1314\n",
              "right       1311\n",
              "save        1308\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Word Frequency of most common words\n",
        "# Split all words with whitespace between them, then put them in word_freq.\n",
        "word_freq_tr = pd.Series(\" \".join(data_tr_clean[\"clean_text\"]).split()).value_counts()\n",
        "word_freq_tr[1:40] # display the first 40 words with frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vopmkeLCsXgX",
        "outputId": "0a418914-d9e9-4569-860d-486e9cd35aa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index  freq\n",
              "0   angriff     1\n",
              "1  delusion     1\n",
              "2      wane     1\n",
              "3  undament     1\n",
              "4      miku     1\n",
              "5    hatsun     1\n",
              "6     nfler     1\n",
              "7    hicock     1\n",
              "8    mccall     1\n",
              "9      wahr     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-758dae99-59d8-4abe-949c-f271ca80b928\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>angriff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delusion</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wane</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>undament</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>miku</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hatsun</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>nfler</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hicock</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>mccall</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wahr</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-758dae99-59d8-4abe-949c-f271ca80b928')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-758dae99-59d8-4abe-949c-f271ca80b928 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-758dae99-59d8-4abe-949c-f271ca80b928');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# display list most uncommon words  \n",
        "# reset_index is reset the index of the DataFrame\n",
        "word_freq_tr[-10:].reset_index(name=\"freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaDrTiC_s7YS",
        "outputId": "385bc4dc-fce4-4c25-ce19-0bd991c3f697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538281\n",
              "1    0.461719\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Distribution of ratings\n",
        "data_tr_clean[\"label\"].value_counts(normalize=True) # count proportions of label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y06v9PRps7au",
        "outputId": "bb8cd843-724f-43cc-a4fd-3973f4fb9a2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(max_df=0.3, min_df=10, ngram_range=(1, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\"\"\"\n",
        "Compute unique word vector with frequencies\n",
        "exclude very uncommon (<10 obsv.) and common (>=30%) words\n",
        "use pairs of two words (ngram)\n",
        "\"\"\"\n",
        "# TfidfVectorizer convert a collection of raw documents to a matrix of TF-IDF features.\n",
        "# min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "# max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "# ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "# ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_df=0.3, min_df=10, ngram_range=(1, 2)\n",
        ")\n",
        "vectorizer.fit(data_tr_clean[\"clean_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37qyZ2dRs7de",
        "outputId": "12f5a7d8-c4a2-4e9a-ce2c-c78590c49c48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique word (ngram) vector extract:\n",
            "\n",
            " eli       2666\n",
            "go far    3595\n",
            "bamboo     650\n",
            "wisdom    9837\n",
            "pocket    6705\n",
            "elf       2665\n",
            "hockey    4027\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Vector representation of vocabulary show some sample from our data_clean\n",
        "word_vector = pd.Series(vectorizer.vocabulary_).sample(7, random_state=1) # By sample, I choose the number of vocabulary that I want to display.\n",
        "print(f\"Unique word (ngram) vector extract:\\n\\n {word_vector}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "5DwjEU01s7f-",
        "outputId": "583de9d0-e95f-4eaa-c380-79c00c28925f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "59995   70046   \n",
              "59996  189377   \n",
              "59997   93486   \n",
              "59998  140950   \n",
              "59999   34509   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          0   \n",
              "3          0   \n",
              "4          0   \n",
              "...      ...   \n",
              "59995      0   \n",
              "59996      1   \n",
              "59997      0   \n",
              "59998      0   \n",
              "59999      1   \n",
              "\n",
              "                                                                                                clean_text  \n",
              "0      group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...  \n",
              "1      british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...  \n",
              "2      goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...  \n",
              "3      happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...  \n",
              "4      obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...  \n",
              "...                                                                                                    ...  \n",
              "59995                                                       finish sniper simo yh invas finland ussr color  \n",
              "59996                                               nigerian princ scam took kansa man year later get back  \n",
              "59997                                                         safe smoke marijuana pregnanc surpris answer  \n",
              "59998                                               julius caesar upon realiz everyon room knife except bc  \n",
              "59999                                        jeff bridg releas leep tape new album design help fall asleep  \n",
              "\n",
              "[59768 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8efc72e-94ca-4d15-8667-26c47fcfbadc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59768 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8efc72e-94ca-4d15-8667-26c47fcfbadc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8efc72e-94ca-4d15-8667-26c47fcfbadc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8efc72e-94ca-4d15-8667-26c47fcfbadc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data_tr_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRQpCfV5vHV_"
      },
      "source": [
        "#####  Splitting data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDNbSd474lfG"
      },
      "source": [
        "I split the data into X and y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6jo-tJ7s7iW"
      },
      "outputs": [],
      "source": [
        "# splitting Trainig data into X_train and y_train\n",
        "X=data_tr_clean['clean_text'] # X contains only clean_text column\n",
        "y=data_tr_clean['label']   # y contains only label column\n",
        "X_test=data_ts['clean_text'] # X_test contains only clean_text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmSW5D2as7lJ",
        "outputId": "a487c4b9-8ea0-4f0a-96ff-2f8eebacfac4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59768, 10061)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# transform each sentence to numeric vector with tf-idf value as elements\n",
        "X_train_vec = vectorizer.transform(X)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "X_train_vec.get_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8_O3uEvvU5t",
        "outputId": "59457c56-12ac-42e2-c66f-322f0f68b1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:\n",
            "['happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorporateshil irish rover jolli rove tar imgur com true dh bqw https extern preview redd qseokdslwivxzdehgxxbceuxh vhemi muoxw yaqq jpg width crop smart auto webp eda ba bf ed fakealbumcov irish rover jolli rove tar kna fire made becam green place redd true cd anx https preview redd nw nexjtfaa jpg width crop smart auto webp ee da ce da mildlyinterest fire made becam green place rhym jarat true cf qh http imgur com crvur jpg wvf psbattl artwork jarat dagnummmong stop redd true qbhc https preview redd lsvmqhtjcz jpg width crop smart auto webp bfb dd ccafa cad fakealbumcov stop top today ss without jupit probabl asteroid impact artist use one vermont senat top surrog year stormtroop finish anim imgur com true cal https extern preview redd vwnj gq tvah fdc ahmc qyzjj sw fqlrwqauk jpg width crop smart auto webp fba de ac subredditsimul without jupit probabl asteroid impact artist use one vermont senat top surrog year stormtroop finish anim jawnboy realm infinit dog chooser divin normal suffer wretch choic incorrect choos wise choos choos choos true https imgur com xfgou jpg iidm psbattl artwork realm infinit dog chooser divin normal suffer wretch choic incorrect choos wise may choos may choos may choos alexkjenkin ask ye shall receiv true https imgur com ibnidfd jpg fcbep psbattl artwork ask ye shall receiv iainesmith frank alway dread part true ccpchlf http imgur com mgnbt jpg zbx psbattl artwork frank alway dread part photoplop marseysid true cp ae http imgur com yseo jpg xkabe psbattl artwork marseysid rotoramm man meal true cypk http imgur com fy wedd jpg zvuch psbattl artwork man meal glen savet snow machin someon driveway redd true ctbeo https preview redd rlt qh jpg width crop smart auto webp ac efd add abfdcc mildlyinterest snow machin someon driveway deathhamst river blind vaccin edg closer ed ac uk true dmjq https extern preview redd yr zogaoiargw cdzp ts ctktfv wzqa oi jpg width crop smart auto webp cc ed upliftingnew river blind vaccin edg closer lasagna boy plant grew gross drain found redd true cvz https preview redd nkebqkn xi jpg width crop smart auto webp ece cdd ea dbf mildlyinterest plant grew gross drain found carwer windsurf southwest imgur com true dr https extern preview redd dczwkjqpxhvvkcckzdopeleq jvt fpqpddquzaltm jpg width crop smart auto webp fe photoshopbattl windsurf southwest lazarus hindu devote gang flickr com true svv https extern preview redd av sjqoxjgu qdlfqqahsekm ro rm gle jpg width crop smart auto webp eb acdaf aa fb cf pic hindu devote gang okthatskooliguess sloucher rebellion redd true gop https preview redd iq dvuf jpg width crop smart auto webp bd ea fakealbumcov sloucher rebellion spamholderman nigeria ebola meme use spread fear virus creat white peopl ibtim co uk true gti https extern preview redd ha vrflokhzf bfmoaltsomovnyco qn ikrplid jpg width crop smart auto webp bf de bfd eead nottheonion nigeria ebola meme use spread fear virus creat white peopl sunflow thrill decay imgur com true ddf https extern preview redd heeeom kpidop djgnzvilo crnxcbotythtdbmgi jpg width crop smart auto webp bfb bc pareidolia sunflow thrill decay royalprincesoldi headbuttbutthead true ck http imgur com jpg ej kd psbattl artwork headbutt butthead jexomwtf heinz ketchunnais redd true byiy https preview redd ev iqv jpg width crop smart auto webp fc ed fec bdad ed mildlyinterest heinz ketchunnais jute siberian villag hope name chang syria get moscow attent rferl org true https extern preview redd wni xj tx bnyhhzhkvyuc ltka ku gsbmn gmo jpg width crop smart auto webp fca edad nottheonion siberian villag hope name chang syria get moscow attent epic snot rocket true csi http imgur com rzxwz jpg cnql psbattl artwork epic snot rocket kogeliz emot support turkey look airplan window imgur com true moc https extern preview redd esofnumep pz dlw ck krcektura jliiaeacxw jpg width crop smart auto webp ae fb cab df ac fdef photoshopbattl psbattl emot support turkey look airplan window psbbot avail true cokn https imgur com hkdvex jpg vsyqp psbattl artwork avail smallszac long babi carrot redd true bx https preview redd exvj jpg width crop smart auto webp bfc baaaae fe mildlyinterest long babi carrot theghostoftzvika disabl lawsuit frequent filer law meant help disabl unintend consequ economist com true https extern preview redd oyyx lnfpyhyjj uz rpn zbtihni qqglxrrzw jpg width crop smart auto webp ab bc ce usanew disabl lawsuit frequent filer law meant help disabl unintend consequ nowordofali obama perman protect one million acr public land thinkprogress org true cwguz https extern preview redd htx xol jh rwx trqo mu rquyn siq jpg width crop smart auto webp eeb de bac upliftingnew obama perman protect one million acr public land kid dive lake imgur com true https extern preview redd crfktocxr htnzkvzqogybelimvq xzcowa jpg width crop smart auto webp fa bc photoshopbattl psbattl kid dive lake raj floor kitchen crack way someth come beneath redd true ad hir https preview redd oqttpk jpg width crop smart auto webp eea fe mildlyinterest floor kitchen crack way someth come beneath id concern danica true cu http imgur com yid jpg hcoki psbattl artwork concern danica darwin icicl gather one tree redd true ccw gq https preview redd lfwaf vn jpg width crop smart auto webp ba ff bbd ec mildlyinterest icicl gather one tree jeffrey picasso left beach dock imgur com true eijow https extern preview redd icqfq qcrhjci ywxgrkconwsitydr yowqmkvbbklm jpg width crop smart auto webp fb pareidolia picasso left beach dock bleepzork play first time post pleas gentl imgur com true https extern preview redd cbm fuwv mrkda ghs wgtil zbdrw oz trzvue gif width crop smart format png dbba misleadingthumbnail play mysel first time post pleas gentl mr bonner hors redd true grr https preview redd ik qq fog jpg width crop smart auto webp cfcc fd ffa ca confus perspect hors flyinghighernow nonprofit back trump deep swampi tie opensecret org true nt https extern preview redd qiwl optgwehxctcxny gasnvoszyhvrbi qbe jpg width crop smart auto webp fd ac ead af dae usnew nonprofit back trump deep swampi tie everybodi dday redd true yia https preview redd wlrdzdl png width crop smart auto webp afbab bffd fakehistoryporn day june color smobuchin beach true ckj http imgur com fwovovo jpg ghq psbattl artwork beach voic wood former ninja warrior save choke man life wkbw com true njkf https extern preview redd bdjmm yvw rvhdd lk qvg surz ag fs jpg width crop smart auto webp fb fddcc cf de ab cb upliftingnew former ninja warrior save choke man life jaw guy pleas pizza imgur com true lqg https extern preview redd exodpupuu ynkz ae tenfbxbx xsmdsj kzftizzmk jpg width crop smart auto webp dfc photoshopbattl guy pleas pizza firecheetah menu nazi death camp restaur redd true cf kg https preview redd ts yxr mm jpg width crop smart auto webp cb fakehistoryporn menu nazi death camp restaur tent phantoka ucc open food pantri assist struggl student gazett com true https extern preview redd nqorl oouo zn tjlilrcnciwkj vat rco jpg width crop smart auto webp fc dde ed aa feb df upliftingnew ucc open food pantri assist struggl student post nottheonion anatoli dyatlov toptunov told reactor explod chernobyl redd true bxjyan https preview redd oc jpg width crop smart auto webp ec ba df aadf fakehistoryporn anatoli dyatlov toptunov told reactor explod chernobyl color elchappiea rain left pattern wood chip redd true tnga https preview redd run cg jpg width crop smart auto webp cc bc bb ea mildlyinterest rain left pattern wood chip provenz alway said small sizeh show true rju http imgur com lo bch jpg uaj psbattl artwork alway said small size show leonickl dont come insid true ly http imgur com adbv jpg api psbattl artwork come insid occamsax interest bit christian found work transcript comment imgur com true coo https extern preview redd vcwniszoibcnykktmsutmyqyasjntramcm jpg width crop smart auto webp ba eaf propagandapost interest bit christian propaganda found work transcript comment mattryd nebraska chicken thief send kfc letter apolog omaha com true https extern preview redd ez kanuczf ruor gcsw xxei cjah pna prkc jpg width crop smart auto webp cbfae de fcab nottheonion nebraska chicken thief send kfc letter apolog gracebatmonkey communiti rescu pumpkin extravaganza disadvantag kid mere hour familiesforlakec com true op jf https extern preview redd mh zz ip ihdcuakvul ftjka ocngz qxsu jpg width crop smart auto webp fd eb ee da fb upliftingnew communiti rescu pumpkin extravaganza disadvantag kid mere hour ftanuki omg buti true ch http imgur com xaxczvk jpg xte psbattl artwork omg buti potallegta man say dollar store trick famili leav houston chron com true dic https extern preview redd nkzktatfpvvddiptaq agzkdo szlypm hie jpg width crop smart auto webp fed af ad de nottheonion man say dollar store trick famili leav houston mjbott imag playboy mansion redd true ldp https preview redd vxmzs png width crop smart auto webp cdd afcec fakehistoryporn imag playboy mansion ignatz marshmallow penguin imgur com true ehdt https extern preview redd xzi lwfz ejioqwa rcuimnfqjg hmejgmk qg lw jpg width crop smart auto webp cd fd cfa cd acda de pareidolia marshmallow penguin wall nose size dog redd true ct https preview redd ewo yxr ph gif width crop smart format png bd cb confus perspect size dog fiskfisk dont panic true cc af http imgur com ie intr jpg lroym psbattl artwork panic']\n",
            "\n",
            "Vector representation of sentence:\n",
            "          aa       ab        ac       acr        ad       add        ae  \\\n",
            "0  0.011699  0.01137  0.027005  0.011329  0.007622  0.004881  0.017896   \n",
            "\n",
            "         af        ag   airplan     alway      anim    apolog    artist  \\\n",
            "0  0.016819  0.006032  0.010488  0.016603  0.007908  0.009554  0.008293   \n",
            "\n",
            "    artwork       ask    assist  asteroid    attent      auto  auto webp  \\\n",
            "0  0.074503  0.007329  0.009865   0.01125  0.010022  0.188691   0.208128   \n",
            "\n",
            "      avail      ave        ba      babi      back        bb        bc  \\\n",
            "0  0.010346  0.00619  0.023738  0.007629  0.006415  0.005685  0.018242   \n",
            "\n",
            "         bd     beach     becam  beneath        bf  birthday       bit  \\\n",
            "0  0.012136  0.016902  0.009176  0.01137  0.011289  0.004315  0.009032   \n",
            "\n",
            "      blind       bob       boy        ca       cab      camp    carrot  \\\n",
            "0  0.009338  0.005183  0.003674  0.004321  0.006106  0.008707  0.011547   \n",
            "\n",
            "         cb        cc        cd        ce        cf        ch     chang  \\\n",
            "0  0.017994  0.017394  0.016559  0.011007  0.023619  0.006068  0.007097   \n",
            "\n",
            "   chernobyl  ...    thrill       tie      time  time post     today  \\\n",
            "0   0.010532  ...  0.011996  0.009422  0.005897   0.012471  0.003519   \n",
            "\n",
            "       told       top  transcript      tree     trick      true  true https  \\\n",
            "0  0.008228  0.011143    0.012064  0.007612  0.009597  0.238112    0.047012   \n",
            "\n",
            "      trump    turkey       tx        uk  upliftingnew       use   use one  \\\n",
            "0  0.005657  0.010037  0.00575  0.008197      0.029246  0.011469  0.012136   \n",
            "\n",
            "     vaccin   vermont   villag     virus     voic      wall   warrior  \\\n",
            "0  0.010289  0.011646  0.00932  0.010857  0.00505  0.003851  0.010405   \n",
            "\n",
            "        way      webp   webp ae   webp ba   webp cb   webp cc   webp cd  \\\n",
            "0  0.006619  0.208128  0.006338  0.012792  0.006396  0.012792  0.006396   \n",
            "\n",
            "    webp eb  webp fa   webp fd   webp fe     white  white peopl     width  \\\n",
            "0  0.006396  0.00619  0.012792  0.006396  0.006925     0.012136  0.216566   \n",
            "\n",
            "   width crop    window      wise   without      wood     work      xi  \\\n",
            "0    0.219378  0.008144  0.012136  0.007829  0.013624  0.00627  0.0053   \n",
            "\n",
            "         ye      year        yr  \n",
            "0  0.012471  0.004979  0.005625  \n",
            "\n",
            "[1 rows x 368 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Compare original comment text with its numeric vector representation\n",
        "print(f\"Original sentence:\\n{X[3:4].values}\\n\")\n",
        "# Feature is a dataframe that takes X_train_vec and converts it to an array, and the column is the name of the feature\n",
        "features = pd.DataFrame(\n",
        "    X_train_vec[3:4].toarray(), columns=vectorizer.get_feature_names()\n",
        ")\n",
        "nonempty_feat = features.loc[:, (features != 0).any(axis=0)]\n",
        "print(f\"Vector representation of sentence:\\n {nonempty_feat}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeDxVFZa5zMT"
      },
      "source": [
        "##### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOSWWp1453xD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "# Further split the original training set to a train and a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, train_size = 0.8, stratify = y, random_state = 2022)\n",
        "\n",
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "# X_train2 (new training set), X_train\n",
        "split_index = [-1 if x in X_train.index else 0 for x in X.index]\n",
        "\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBKM7B8LDl4R"
      },
      "source": [
        "## **Trials ( Word-level Vectorizer )**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfzDqPRcDtty"
      },
      "source": [
        "### **Naural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq8suBMAD5Qq"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y0oQAieGUrA"
      },
      "source": [
        "* I will use the **MLPClassifier** with:\n",
        " * solver = adam\n",
        " * size of hidden layer = 12 in each layers\n",
        " * ReLU as activation function\n",
        " * Use early stoppping to avoid overfitting\n",
        " * n_iter_no_change = 1\n",
        "* I will use **Random** search in tuning.\n",
        "* **word**-level vectorizer\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.75 and 0.80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw3_7Ecz5tYd"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keAY9lmG5ux7",
        "outputId": "6fdafebc-3cd3-4ba2-fd95-7f92269d5a42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8619907522969671\n",
            "best score {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 8, 'tfidf__max_df': 0.3}\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ))])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjDHpkzI5u0z"
      },
      "outputs": [],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt2LQuBK-fp_"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 33\n",
        "* max_df = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWjAUlFu5u-T"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csmlO-3Q-lX0"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3SW0a0W-lX1"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.8619 \\\n",
        "Accuracy in **kaggle** =0.82320"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe88Y-jkIQqN"
      },
      "source": [
        "#### **Trial 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_XXtl6dIQqO"
      },
      "source": [
        "Accordding to previous trial I will use the same classifier but i will use **Bayes** Search instaed of Random search\\\n",
        "**My thoughts and observations :** The accuracy would be between 0.82320 and 0.8250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecp-D9bBIQqO"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRXf1qqlIQqO",
        "outputId": "a3c6d765-5bfd-4659-9bb1-bfe6916c3ae0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8606024283139703\n",
            "best score OrderedDict([('tfidf__max_df', 0.3), ('tfidf__min_df', 8)])\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ))])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "}\n",
        "\n",
        "pipe_clf = BayesSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Bayes search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vY5Pjrt0IQqO"
      },
      "outputs": [],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAltnDCOIQqO"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 8\n",
        "* max_df = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJPdHNfcIQqP"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44vd1yaIQqP"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNLHgPmUIQqP"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.8606 \\\n",
        "Accuracy in **kaggle** =0.81479 \\\n",
        "The previous trial is better than this trial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3TH-yySIRPF"
      },
      "source": [
        "#### **Trial 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef-ywqd6IRPG"
      },
      "source": [
        "* Accordding to previous trial I will **change hyperparameters**:\n",
        " * solver = lbfgs\n",
        " * size of hidden layer = 12 in each layers\n",
        " * ReLU as activation function\n",
        " * Use early stoppping to avoid overfitting\n",
        " * alpha = 0.0001\n",
        " * learning_rate =adaptive\n",
        "* I will use **Random** search in tuning.\\\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.82320 and 0.8250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZVlbwgtIRPH"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ECuHkAIRPH",
        "outputId": "aef04799-03a6-43d6-e336-b61039004ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8504907747524162\n",
            "best score {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 17, 'tfidf__max_df': 0.3}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver='lbfgs',\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        alpha=0.0001,\n",
        "        learning_rate= 'adaptive',\n",
        "    ))])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7QhrL_HIRPJ",
        "outputId": "3df42ae3-3833-4db6-86d5-41a98602f888"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DvyX9DSIRPJ"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 17\n",
        "* max_df = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I646oHymIRPJ"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-9zt3wuIRPK"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPCpCgNZIRPK"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.85049 \\\n",
        "Accuracy in **kaggle** =0.82669\\\n",
        "This trial is better than all previous trials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxuFSYtBOE8-"
      },
      "source": [
        "### **XGBoost Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKETHVt3OE9W"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh3EI4bgOE9W"
      },
      "source": [
        "* I will use the **XGBClassifier** with:\n",
        " * min_child_weight = [20,40,80]\n",
        " * max_depth = [50,60,70]\n",
        " * gamma = [0.5, 1, 1.5, 2, 5]\n",
        " * colsample_bytree = [0.6, 0.8, 1.0]\n",
        "* I will use **Random** search in tuning.\n",
        "* **word**-level vectorizer\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.0.82 and 0.83"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeQlhoajOE9X"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLoLccpxOE9X",
        "outputId": "769959a6-bd78-4ee7-fb51-3eeeeb947dde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8311641791801241\n",
            "best score {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 9, 'tfidf__max_df': 0.3, 'my_classifier__min_child_weight': 20, 'my_classifier__max_depth': 70, 'my_classifier__gamma': 0.5, 'my_classifier__colsample_bytree': 0.6}\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  XGBClassifier())])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "    'my_classifier__min_child_weight': [20,40,80],\n",
        "    # min_child_weight is a minimal total of the weights in a child.\n",
        "    'my_classifier__max_depth':[50,60,70],  \n",
        "    # max_depth is a maximum depth of a tree\n",
        "    'my_classifier__gamma':[0.5, 1, 1.5, 2, 5],\n",
        "    # gamma is a minimum loss that we need it to split tree\n",
        "    'my_classifier__colsample_bytree':[0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0hWsJEPOE9Y"
      },
      "outputs": [],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRqN4DS-OE9Y"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 9\n",
        "* max_df = 0.3\n",
        "* min_child_weight = 20\n",
        "* max_depth = 70 (When increasing max_depth, the accuracy gets better)\n",
        "* gamma = 0.5\n",
        "* colsample_bytree = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYZ7p8oxOE9Z"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFnrhL-lOE9Z"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWgUDRTzOE9Z"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.83116\\\n",
        "Accuracy in **kaggle** = 0.80296"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax1UnBTbT_sp"
      },
      "source": [
        "### **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-co-fl0xT_s6"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiiFfV-yT_s6"
      },
      "source": [
        "* I will use the **LogisticRegression** with:\n",
        " * c = 100\n",
        " * max_iter = 100\n",
        " * tol = [1e-4,1e-5,1e-3]\n",
        "* I will use **Grid** search in tuning.\n",
        "* **word**-level vectorizer\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.80 and 0.82"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y81hcIdXT_s6"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDqm3y0OT_s6",
        "outputId": "5c7b5125-23ad-4eb3-97d8-5f6137d7cc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 570 candidates, totalling 570 fits\n",
            "best score 0.852913232003647\n",
            "best score {'my_classifier__C': 100, 'my_classifier__max_iter': 100, 'my_classifier__tol': 0.0001, 'tfidf__max_df': 0.3, 'tfidf__min_df': 27, 'tfidf__ngram_range': (1, 2)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  LogisticRegression())])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "    'my_classifier__C': [100],\n",
        "    # C controls the penality strength \n",
        "    # my_classifier__C points to my_classifier->C\n",
        "    'my_classifier__max_iter':[100], \n",
        "    # max_iter is a maximum number of iterations\n",
        "    # my_classifier__max_iter points to my_classifier-> max_iter\n",
        "    'my_classifier__tol':[1e-4,1e-5,1e-3]\n",
        "    # tol is a tolerance for stopping\n",
        "    # my_classifier__tol points to my_classifier-> tol\n",
        "\n",
        "}\n",
        "\n",
        "pipe_clf = GridSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Grid search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku95BSC2T_s7",
        "outputId": "f8c0eef9-54ec-4e99-f244-9f2cb5cba840"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gERXQzmsT_s7"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 27\n",
        "* max_df = 0.3\n",
        "* C = 100\n",
        "* max_iter = 100\n",
        "* tol = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RIBqm_iT_s7"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZ1tfqodT_s7"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7JENmadT_s7"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.85291 \\\n",
        "Accuracy in **kaggle** =0.80995"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OukgEy3T_s7"
      },
      "source": [
        "#### **Trial 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbQS-KTQT_s7"
      },
      "source": [
        "Accordding to previous trial I will use the same classifier but\n",
        "*  I will use **Bayes** Search instead of Grid search\n",
        "* Change hyperparameter values\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.80995 and 0.81955"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSDw1W7vT_s7"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj2AnMKTT_s8",
        "outputId": "d812d4b7-8835-4640-9d49-4164911402d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.8498690615016036\n",
            "best score OrderedDict([('my_classifier__C', 300), ('my_classifier__max_iter', 200), ('my_classifier__tol', 1e-05), ('tfidf__max_df', 0.3), ('tfidf__min_df', 27)])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  LogisticRegression())])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "    'my_classifier__C': [100,200,300],\n",
        "    # C controls the penality strength \n",
        "    # my_classifier__C points to my_classifier->C\n",
        "    'my_classifier__max_iter':[100 ,200, 300], \n",
        "    # max_iter is a maximum number of iterations\n",
        "    # my_classifier__max_iter points to my_classifier-> max_iter\n",
        "    'my_classifier__tol':[1e-4,1e-5,1e-3]\n",
        "    # tol is a tolerance for stopping\n",
        "    # my_classifier__tol points to my_classifier-> tol\n",
        "\n",
        "}\n",
        "\n",
        "pipe_clf = BayesSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Q7UTOTz6T_s8",
        "outputId": "81ebb09f-cb06-4f4c-d3ab-3f05f29e5cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXMx0HJvT_s8"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 27\n",
        "* max_df = 0.3\n",
        "* C = 300\n",
        "* max_iter = 200\n",
        "* tol = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EOOW9Pb4T_s8"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdd1r1xBT_s8"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6KRxkVsT_s8"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.8498 \\\n",
        "Accuracy in **kaggle** =0.82423 \\\n",
        "This trial is better than The previous trial and it is better than I thought."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UurAtB4Oomlv"
      },
      "source": [
        "### **Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO7olZ5loml1"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Z0SsF9oml1"
      },
      "source": [
        "* I will use the **RandomForestClassifier** with:\n",
        " * n_estimators = [170,200,250]\n",
        " * max_depth = [70,80,90]\n",
        " * max_features = [10,20,30]\n",
        "* I will use **Random** search in tuning.\n",
        "* **word**-level vectorizer\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.81 and 0.82"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQeYfABXoml1"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZXs7QP0oml1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080ceb1b-b72d-4bb3-bcf7-bdd142a2f7da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8462690658378282\n",
            "best score {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 8, 'tfidf__max_df': 0.3, 'my_classifier__n_estimators': 170, 'my_classifier__max_features': 10, 'my_classifier__max_depth': 80}\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"word\", norm=\"l2\")), (\"my_classifier\",  RandomForestClassifier())])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "    'my_classifier__n_estimators': [170,200,250],\n",
        "    # n_estimators is a number of trees \n",
        "    # my_classifier__n_estimators points to my_classifier->n_estimators\n",
        "    'my_classifier__max_depth':[70,80,90],   \n",
        "    # max_depth is a maximum depth of the tree\n",
        "    # my_classifier__max_depth points to my_classifier-> max_depth\n",
        "    'my_classifier__max_features':[10,20,30]\n",
        "    # max_features is a maximum number of features\n",
        "    # my_classifier__max_features points to my_classifier-> max_features\n",
        "\n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKVv_Af9oml2"
      },
      "outputs": [],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7y0dRvoml2"
      },
      "source": [
        "Best paramters:\n",
        "* ngram_range = (1, 3)\n",
        "* min_df = 8\n",
        "* max_df = 0.3\n",
        "* n_estimators = 170\n",
        "* max_features = 10\n",
        "* max_depth = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3rfY6jZoml2"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6KgflBFoml2"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eya-2_H5oml2"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.84626 \\\n",
        "Accuracy in **kaggle** =0.81024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2kRfwlUsaT7"
      },
      "source": [
        "## **Trials ( Character-level Vectorizer )**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qTokW05saT8"
      },
      "source": [
        "### **Naural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H_eaFyfsaUA"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wash0bbWsaUA"
      },
      "source": [
        "* In this trial I will use Naural Network with:\n",
        " * solver = lbfgs\n",
        " * size of hidden layer = 12 in each layers\n",
        " * ReLU as activation function\n",
        " * Use early stoppping to avoid overfitting\n",
        " * alpha = 0.0001\n",
        " * learning_rate =adaptive\n",
        "* I will use **Random** search in tuning.\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.73 and 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K-ST3qXsaUA"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yoyJVHDsaUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af238407-655f-4d3b-f7c6-3963525e167b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 10 candidates, totalling 10 fits\n",
            "best score 0.8242078752316113\n",
            "best score {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 6, 'tfidf__max_df': 0.3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"my_classifier\",  MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver='lbfgs',\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        alpha=0.0001,\n",
        "        learning_rate= 'adaptive',\n",
        "    ))])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1, 2), (1, 3)],\n",
        "    # tfidf__ngram_range points to TfidfVectorizer -> ngram_range\n",
        "    # ngram_range Two words have a higher correlation than the threshold and frequently appear together.\n",
        "    # ngram_range=(a,b)-> a is the minimum and b is the maximum size of ngrams\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "}\n",
        "\n",
        "pipe_clf = RandomizedSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u23oy6GksaUA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fb3bec9-86cb-461b-e90a-ba2114d63ea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-IGNASsaUA"
      },
      "source": [
        "Best paramters:\n",
        "* ngram_range = (1,3)\n",
        "* min_df = 6\n",
        "* max_df = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGvGc3O-saUB"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neVXPqefsaUB"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOL3dtMjsaUB"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.8242 \\\n",
        "Accuracy in **kaggle** =0.76849\\\n",
        "It is better than I thought."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvEIQ-tUsaUC"
      },
      "source": [
        "### **Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6l6dHSnsaUD"
      },
      "source": [
        "#### **Trial 0**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLyfgG6isaUD"
      },
      "source": [
        "* I will use the **LogisticRegression** with:\n",
        " * c = [100,200,300]\n",
        " * max_iter = [100,200,300]\n",
        " * tol = [1e-4,1e-5,1e-3]\n",
        "* I will use **Bayes** search in tuning.\n",
        "* **Char**-level vectorizer\n",
        "\n",
        "**My thoughts and observations :** The accuracy would be between 0.70 and 0.75"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLN3yZnsaUD"
      },
      "source": [
        "##### PipeLine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxUzLXqrsaUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ceeaaf-bec3-4828-d0be-afaa5d5f35c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.5376064011686406\n",
            "best score OrderedDict([('my_classifier__C', 100), ('my_classifier__max_iter', 100), ('my_classifier__tol', 1e-05), ('tfidf__max_df', 0.3), ('tfidf__min_df', 28)])\n"
          ]
        }
      ],
      "source": [
        "# Built pipline\n",
        "# The pipeline's goal is to combine numerous processes that can be cross-validated while modifying various parameters.\n",
        "# It does this by allowing set parameters for each step using their names and parameter names separated by a \"__\"\n",
        "# It takes steps as a prameter that contain all the preprocessing, vectorization, and normalization that I need.\n",
        "# It saves time by applying any preprocessing to both train and test data without repeating the process.\n",
        "\n",
        "pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer=\"char\", norm=\"l2\")), (\"my_classifier\",  LogisticRegression())])\n",
        "\n",
        "# define parameter space to test\n",
        "params = {\n",
        "    \"tfidf__max_df\": np.arange(0.3, 0.8),\n",
        "    # max_df ignore terms that have a document frequency strictly higher than the given threshold\n",
        "    \"tfidf__min_df\": np.arange(5, 100),\n",
        "    # min_df ignore terms that have a document frequency strictly lower than the given threshold\n",
        "    'my_classifier__C': [100,200,300],\n",
        "    # C controls the penality strength \n",
        "    # my_classifier__C points to my_classifier->C\n",
        "    'my_classifier__max_iter':[100 ,200, 300], \n",
        "    # max_iter is a maximum number of iterations\n",
        "    # my_classifier__max_iter points to my_classifier-> max_iter\n",
        "    'my_classifier__tol':[1e-4,1e-5,1e-3]\n",
        "    # tol is a tolerance for stopping\n",
        "    # my_classifier__tol points to my_classifier-> tol\n",
        "\n",
        "}\n",
        "\n",
        "pipe_clf = BayesSearchCV(\n",
        "    pipe, params, cv=pds, verbose=1, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "# here we still use X but the Randomized search model by use validation set \n",
        "# fit the pipeline\n",
        "pipe_clf.fit(X, y)\n",
        "\n",
        "print('best score {}'.format(pipe_clf.best_score_))\n",
        "print('best score {}'.format(pipe_clf.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI6b17g8saUD"
      },
      "outputs": [],
      "source": [
        "# run pipe with optimized parameters\n",
        "best_params = pipe_clf.best_params_\n",
        "pipe.set_params(**best_params).fit(X, y)\n",
        "pipe_pred = pipe.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTxiPr02saUD"
      },
      "source": [
        "Best paramters:\n",
        "* min_df = 28\n",
        "* max_df = 0.3\n",
        "* C = 100\n",
        "* max_iter = 100\n",
        "* tol = 1e-05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Kut08X9saUE"
      },
      "outputs": [],
      "source": [
        "# Use this cell to write the result in the excel sheet.\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = data_ts['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "submission.to_csv('/content/drive/MyDrive/Queens_Practical/Data_Mining/compt3/sample_submission_walkthrough.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ_fY-2CsaUE"
      },
      "source": [
        "##### Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJpLQn0xsaUE"
      },
      "source": [
        "Accuracy in **Cross-Validation** = 0.5376 \\\n",
        "Accuracy in **kaggle** =0.46892 \\\n",
        "The previous trial is better than This trial and it is worse than I thought"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx1nhMOT0lDP"
      },
      "source": [
        "# **Questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r06ocOEWwbD0"
      },
      "source": [
        "**What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?** \\\n",
        "- Character n-gram divide text into a set of characters.\n",
        "- Word n-gram divide text into words.\n",
        "- Word n-gram suffer more from the OOV issue\n",
        "\n",
        "**What is the difference between stop word removal and stemming? Are these techniques language-dependent?** \\\n",
        "- **Stopwords** are the most common words in any natural language, and they may offer little value to the document's meaning.\n",
        "- **Stemming** is used to return the word to its original form(root form) By slicing off the end or beginning of a word and taking in a list of common prefixes and suffixes that could appear in that word.\n",
        "- **Yes**, these are language-dependent.\n",
        "\n",
        "**Is tokenization techniques language dependent? Why?** \\\n",
        "- yes, because there are some words that exist in different languages but may have the same or different sounds, and the meaning.\n",
        "\n",
        "**What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?** \\\n",
        "-  **CountVectorizer** focuses on the frequency of words ( number of times words appear ) in the document but **TF-IDF** focuses on the frequency of words, and that's important, so we can remove less important words. Model complexity will be reduced by reducing the input dimension.\n",
        "- No, It is selected by the try and error and hyperparameter search methods.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "xtuxWrmAvyuK",
        "7opYAnLnap5E",
        "inwm5qPoGMGh",
        "2ZDj6MYdbJE8",
        "FUNKxyseA-_E",
        "DRQpCfV5vHV_",
        "yeDxVFZa5zMT",
        "gBKM7B8LDl4R",
        "WfzDqPRcDtty",
        "Nq8suBMAD5Qq",
        "mw3_7Ecz5tYd",
        "csmlO-3Q-lX0",
        "Oe88Y-jkIQqN",
        "ecp-D9bBIQqO",
        "a44vd1yaIQqP",
        "H3TH-yySIRPF",
        "xZVlbwgtIRPH",
        "O-9zt3wuIRPK",
        "HxuFSYtBOE8-",
        "fKETHVt3OE9W",
        "YeQlhoajOE9X",
        "IFnrhL-lOE9Z",
        "Ax1UnBTbT_sp",
        "-co-fl0xT_s6",
        "y81hcIdXT_s6",
        "LZ1tfqodT_s7",
        "9OukgEy3T_s7",
        "mSDw1W7vT_s7",
        "mdd1r1xBT_s8",
        "UurAtB4Oomlv",
        "mO7olZ5loml1",
        "CQeYfABXoml1",
        "q6KgflBFoml2",
        "N2kRfwlUsaT7",
        "3qTokW05saT8",
        "9H_eaFyfsaUA",
        "_K-ST3qXsaUA",
        "neVXPqefsaUB",
        "uvEIQ-tUsaUC",
        "Y6l6dHSnsaUD",
        "MQLN3yZnsaUD",
        "zJ_fY-2CsaUE",
        "tx1nhMOT0lDP"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}